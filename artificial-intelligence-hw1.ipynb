{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:15.375869Z",
     "iopub.status.busy": "2023-10-03T10:01:15.375500Z",
     "iopub.status.idle": "2023-10-03T10:01:15.381509Z",
     "shell.execute_reply": "2023-10-03T10:01:15.380528Z",
     "shell.execute_reply.started": "2023-10-03T10:01:15.375847Z"
    },
    "id": "SxLocTk5XBRt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.optim import optimizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義 Regression 的類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:15.383261Z",
     "iopub.status.busy": "2023-10-03T10:01:15.382985Z",
     "iopub.status.idle": "2023-10-03T10:01:15.395396Z",
     "shell.execute_reply": "2023-10-03T10:01:15.394145Z",
     "shell.execute_reply.started": "2023-10-03T10:01:15.383233Z"
    },
    "id": "Mao995H-Xhgi"
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.net = nn.Sequential (\n",
    "            nn.Linear(input_dim,output_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(input_dim,8),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(8,output_dim),\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLmiJv9LXlil"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:15.398348Z",
     "iopub.status.busy": "2023-10-03T10:01:15.397871Z",
     "iopub.status.idle": "2023-10-03T10:01:16.112623Z",
     "shell.execute_reply": "2023-10-03T10:01:16.112058Z",
     "shell.execute_reply.started": "2023-10-03T10:01:15.398314Z"
    },
    "id": "TP1ivTxCXqMI",
    "outputId": "ff9b186e-244a-4cb8-e690-9390c4c00a91"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 916 is out of bounds for axis 0 with size 916",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 102\u001b[0m\n\u001b[0;32m    100\u001b[0m ti \u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m    101\u001b[0m tj \u001b[38;5;241m=\u001b[39m j\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(train_df\u001b[38;5;241m.\u001b[39miloc[tj,ti] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    103\u001b[0m     tj \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    104\u001b[0m end \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39miloc[tj,ti]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1066\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1064\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m-> 1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3915\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   3913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m takeable:\n\u001b[0;32m   3914\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 3915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[0;32m   3917\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(col)\n\u001b[0;32m   3918\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n",
      "\u001b[1;31mIndexError\u001b[0m: index 916 is out of bounds for axis 0 with size 916"
     ]
    }
   ],
   "source": [
    "def load_data(folder_path):\n",
    "    load_df = pd.DataFrame()\n",
    "  # 遍歷文件夾中的所有文件\n",
    "    name_list=[]\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            count = 0\n",
    "            date_list = []\n",
    "            for i in range(len(df[\"Date\"])-1,-1, -1):\n",
    "                date_string = df[\"Date\"][i]\n",
    "                dt = datetime.strptime(date_string, '%Y-%m-%d')\n",
    "                date_list.append(dt)\n",
    "                count = 1\n",
    "            i = len(date_list) - 1  # 從列表的最後一個元素開始\n",
    "            while i >= 0:\n",
    "                if i == 0:\n",
    "                    if count < 5:\n",
    "                        for j in range(count):\n",
    "                            del date_list[i-j]\n",
    "                    break\n",
    "                else:\n",
    "                    if date_list[i] - timedelta(days=1) == date_list[i-1]:\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        if count < 5:\n",
    "                            for j in range(count):\n",
    "                                del date_list[i-j]\n",
    "                            count = 1\n",
    "                        else:\n",
    "                            count = 1\n",
    "                    i -= 1  # 向前移動 \n",
    "            i = 0\n",
    "            j = 0\n",
    "            \n",
    "            # 將 'Date' 欄位轉換為 datetime\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            date_set = set(date_list)\n",
    "            mask = df[\"Date\"].isin(date_set)\n",
    "            df = df[mask]\n",
    "            df = df.sort_values(by=\"Date\")\n",
    "            df['Date'] = df['Date'].dt.strftime(('%Y-%m-%d'))\n",
    "            df.set_index(df['Date'], inplace=True)\n",
    "\n",
    "#             if filename == \"AUD.csv\":\n",
    "#                 print (df)\n",
    "#             load_df = pd.concat([load_df, df[\"Date\"], df[\"現鈔買入\"], df[\"現鈔賣出\"], df[\"即期買入\"], df[\"即期賣出\"]], axis=1)\n",
    "            \n",
    "#             print(load_df)\n",
    "            load_df = pd.concat([load_df, df[\"現鈔買入\"]], axis=1)\n",
    "#             load_df.fillna(0, inplace=True)\n",
    "            filename = filename.replace(\".csv\", \"\")\n",
    "            name_list.extend([f\"{filename}現鈔買入\"])\n",
    "#             name_list.extend([f\"{filename}Date\", f\"{filename}現鈔買入\", f\"{filename}現鈔賣出\", f\"{filename}即期買入\", f\"{filename}即期賣出\"])\n",
    "#     print(name_list)\n",
    "#     print(load_df)\n",
    "    load_df.columns = name_list\n",
    "  # 反向排序\n",
    "#     load_df = load_df.iloc[::-1]\n",
    "    \n",
    "  # 排序column\n",
    "    load_df = load_df.reindex(sorted(load_df.columns), axis=1)\n",
    "\n",
    "  # 處理空值\n",
    "#     load_df.replace(\"-\", 0, inplace=True)\n",
    "#     load_df.fillna(0, inplace=True)\n",
    "  #print(load_df)\n",
    "    return load_df\n",
    "\n",
    "#Kaggle 的路徑!!\n",
    "# train_df = load_data(\"/kaggle/input/2023-artificial-intelligence-hw1/Dataset/train\")\n",
    "\n",
    "\n",
    "\n",
    "train_df = load_data(\"./Dataset/train\")\n",
    "\n",
    "\n",
    "# train_df['AUDDate'] = pd.to_datetime(train_df['AUDDate'])\n",
    "# train_df = train_df.sort_values(by='AUDDate')\n",
    "# train_df.replace(\"-\", 0, inplace=True)\n",
    "# train_df.replace(\"NaN\",0, inplace=True)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "# pd.reset_option('display.max_rows')\n",
    "# pd.reset_option('display.max_columns')\n",
    "# pd.reset_option('display.expand_frame_repr')\n",
    "# train_df['AUDDate'] = train_df['AUDDate'].dt.strftime(('%Y-%m-%d'))\n",
    "\n",
    "train_df.replace(\"-\", 0, inplace=True)\n",
    "train_df.fillna(0, inplace=True)\n",
    "\n",
    "first_time = True\n",
    "for i in range(len(train_df.columns)): #make the 0 be the half of the value numbers start and end\n",
    "    for j in range(len(train_df)):\n",
    "        start = 0\n",
    "        if train_df.iloc[j,i] == 0:\n",
    "            front = train_df.iloc[j-1,i]\n",
    "            ti = i\n",
    "            tj = j\n",
    "            while(train_df.iloc[tj,ti] == 0):\n",
    "                tj += 1\n",
    "            end = train_df.iloc[tj,ti]\n",
    "            if first_time:\n",
    "                first_time = False\n",
    "                print(front,end)\n",
    "            half = (front + end)/2\n",
    "            half = round(half, 2)\n",
    "            train_df.iloc[j,i] = half\n",
    "            \n",
    "train_df.reset_index(drop=True, inplace=True)  # 重置索引，丢弃原有索引\n",
    "print(train_df.shape)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTcoZmLiczz6"
   },
   "source": [
    "## Preprocess\n",
    "這邊的做法會以前四天的資料，來預測出第五天的結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:16.113674Z",
     "iopub.status.busy": "2023-10-03T10:01:16.113314Z",
     "iopub.status.idle": "2023-10-03T10:01:16.118590Z",
     "shell.execute_reply": "2023-10-03T10:01:16.117596Z",
     "shell.execute_reply.started": "2023-10-03T10:01:16.113656Z"
    },
    "id": "iPF5YLp2c8wd"
   },
   "outputs": [],
   "source": [
    "# 設定輸入資料的天數範圍\n",
    "input_date_data_size = 4\n",
    "\n",
    "# 設定 seed\n",
    "torch.manual_seed(66)\n",
    "np.random.seed(66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:16.121715Z",
     "iopub.status.busy": "2023-10-03T10:01:16.121389Z",
     "iopub.status.idle": "2023-10-03T10:01:16.139709Z",
     "shell.execute_reply": "2023-10-03T10:01:16.138431Z",
     "shell.execute_reply.started": "2023-10-03T10:01:16.121694Z"
    },
    "id": "ZH374JbtdXWT",
    "outputId": "63f85bbf-64e2-47c6-b25f-5a3db34ab16e"
   },
   "outputs": [],
   "source": [
    "train = train_df.to_numpy()\n",
    "train_size, feature_size = train.shape\n",
    "# 以一段時間的資料當作輸入，故資料數量要扣掉輸入天數範圍\n",
    "train_size = train_size - input_date_data_size\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:16.140954Z",
     "iopub.status.busy": "2023-10-03T10:01:16.140699Z",
     "iopub.status.idle": "2023-10-03T10:01:16.164394Z",
     "shell.execute_reply": "2023-10-03T10:01:16.163117Z",
     "shell.execute_reply.started": "2023-10-03T10:01:16.140935Z"
    },
    "id": "eQK4QS0Edn9h",
    "outputId": "d101d6e9-c747-4d61-aac7-e5ba286b862c"
   },
   "outputs": [],
   "source": [
    "train_x = np.empty([train_size, feature_size * input_date_data_size], dtype = float)\n",
    "train_y = np.empty([train_size, feature_size], dtype = float)\n",
    "\n",
    "for idx in range(train_size):\n",
    "  temp_data = np.array([])\n",
    "  for count in range(input_date_data_size):\n",
    "    temp_data = np.hstack([temp_data, train[idx + count]])\n",
    "  train_x[idx, :] = temp_data\n",
    "  train_y[idx, :] = train[idx + input_date_data_size]\n",
    "# y值只留下現鈔買入\n",
    "filtered_columns = [train_df.columns.get_loc(col) for col in train_df.columns if '現鈔買入'in col]\n",
    "train_y = train_y[:, filtered_columns]\n",
    "train_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RugD2D1IocN"
   },
   "source": [
    "## Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:16.166184Z",
     "iopub.status.busy": "2023-10-03T10:01:16.165864Z",
     "iopub.status.idle": "2023-10-03T10:01:16.195827Z",
     "shell.execute_reply": "2023-10-03T10:01:16.195093Z",
     "shell.execute_reply.started": "2023-10-03T10:01:16.166160Z"
    },
    "id": "gMLavS1oIr5X"
   },
   "outputs": [],
   "source": [
    "mean_x = np.mean(train_x, axis = 0)\n",
    "std_x = np.std(train_x, axis = 0)\n",
    "for i in range(len(train_x)):\n",
    "    for j in range(len(train_x[0])):\n",
    "        if std_x[j] != 0:\n",
    "            train_x[i][j] = (train_x[i][j] - mean_x[j]) / std_x[j]\n",
    "            \n",
    "# train_y = np.array(train_y)\n",
    "            \n",
    "# mean_y = np.mean(train_y, axis = 0)\n",
    "# std_y = np.std(train_y, axis = 0)\n",
    "# for i in range(len(train_y)):\n",
    "#     for j in range(len(train_y[0])):\n",
    "#         if std_y[j] != 0:\n",
    "#             train_y[i][j] = (train_y[i][j] - mean_y[j]) / std_y[j]\n",
    "\n",
    "# train_x, train_y\n",
    "\n",
    "# train_x = np.nan_to_num(train_x, nan=0)\n",
    "\n",
    "# min_val = np.min(train_x, axis=0)\n",
    "# max_val = np.max(train_x, axis=0)\n",
    "# print(train_x[0],min_val,max_val)\n",
    "\n",
    "# for i in range(len(train_x)):\n",
    "#     for j in range(len(train_x[0])):\n",
    "#         if max_val[j] - min_val[j] != 0:\n",
    "#             train_x[i][j] = (train_x[i][j] - min_val[j]) / (max_val[j] - min_val[j])\n",
    "#         else:\n",
    "#             train_x[i][j] = (train_x[i][j] - min_val[j])\n",
    "# train_x[0],min_val,max_val\n",
    "\n",
    "# row_sums = train_x.sum(axis=1)\n",
    "# new_matrix = train_x / row_sums[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHVq7r1_tRe7"
   },
   "source": [
    "## Split Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:16.197687Z",
     "iopub.status.busy": "2023-10-03T10:01:16.196828Z",
     "iopub.status.idle": "2023-10-03T10:01:16.203214Z",
     "shell.execute_reply": "2023-10-03T10:01:16.202222Z",
     "shell.execute_reply.started": "2023-10-03T10:01:16.197655Z"
    },
    "id": "RNeKnFzesW_s"
   },
   "outputs": [],
   "source": [
    "split_ratio = 0.2\n",
    "\n",
    "# 計算驗證集的大小\n",
    "val_size = int(train_size * split_ratio)\n",
    "\n",
    "# 隨機生成索引以選擇要包含在驗證集中的樣本\n",
    "indices = np.random.permutation(train_size)\n",
    "\n",
    "# 使用索引切分數據\n",
    "val_indices = indices[:val_size]\n",
    "train_indices = indices[val_size:]\n",
    "\n",
    "# 創建訓練集和驗證集\n",
    "val_x = train_x[val_indices]\n",
    "val_y = train_y[val_indices]\n",
    "\n",
    "train_x = train_x[train_indices]\n",
    "train_y = train_y[train_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jysPrpk5Iwt_"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:16.205198Z",
     "iopub.status.busy": "2023-10-03T10:01:16.204895Z",
     "iopub.status.idle": "2023-10-03T10:01:16.224915Z",
     "shell.execute_reply": "2023-10-03T10:01:16.223659Z",
     "shell.execute_reply.started": "2023-10-03T10:01:16.205180Z"
    },
    "id": "7nTagJcqIx5v"
   },
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(train_x.astype(np.float32))\n",
    "train_y = torch.from_numpy(train_y.astype(np.float32))\n",
    "val_x = torch.from_numpy(val_x.astype(np.float32))\n",
    "val_y = torch.from_numpy(val_y.astype(np.float32))\n",
    "print(train_x[0],train_y[0],val_x[0],val_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:16.228508Z",
     "iopub.status.busy": "2023-10-03T10:01:16.227247Z",
     "iopub.status.idle": "2023-10-03T10:01:16.233369Z",
     "shell.execute_reply": "2023-10-03T10:01:16.232622Z",
     "shell.execute_reply.started": "2023-10-03T10:01:16.228458Z"
    },
    "id": "DUCjwpH2MGvl"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(feature_size * input_date_data_size, 8)\n",
    "\n",
    "# learning_rate = 0.01\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.001, total_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:01:16.236089Z",
     "iopub.status.busy": "2023-10-03T10:01:16.234672Z",
     "iopub.status.idle": "2023-10-03T10:07:25.702457Z",
     "shell.execute_reply": "2023-10-03T10:07:25.701722Z",
     "shell.execute_reply.started": "2023-10-03T10:01:16.236048Z"
    },
    "id": "NLvDBlIRMVAM",
    "outputId": "27822b83-88ae-4dd5-b0c4-d38862066fe0"
   },
   "outputs": [],
   "source": [
    "epochs = 1000000\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch == 10000:\n",
    "        learning_rate = learning_rate*0.1\n",
    "    if epoch == 100000:\n",
    "        learning_rate = learning_rate*0.1\n",
    "    model.train()\n",
    "    # forward pass and loss\n",
    "    train_y_predicted = model(train_x)\n",
    "    loss = criterion(train_y_predicted, train_y)\n",
    "    train_loss_history.append(loss.item())\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # update\n",
    "    optimizer.step()\n",
    "    # init optimizer\n",
    "    optimizer.zero_grad()\n",
    "#     before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "#     scheduler.step()\n",
    "#     after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "#     print(\"Epoch %d: SGD lr %.4f -> %.4f\" % (epoch, before_lr, after_lr))\n",
    "\n",
    "\n",
    "    # 驗證資料集\n",
    "    model.eval()\n",
    "    val_y_predicted = model(val_x)\n",
    "    val_loss = criterion(val_y_predicted, val_y)\n",
    "    val_loss_history.append(val_loss.item())\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, train_loss = {loss.item(): .4f}, val_loss = {val_loss.item(): .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlYBy1PwyV7o"
   },
   "source": [
    "## Chart drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:07:25.704063Z",
     "iopub.status.busy": "2023-10-03T10:07:25.703657Z",
     "iopub.status.idle": "2023-10-03T10:07:28.606053Z",
     "shell.execute_reply": "2023-10-03T10:07:28.604998Z",
     "shell.execute_reply.started": "2023-10-03T10:07:25.704039Z"
    },
    "id": "l_ajMwiwwgCl",
    "outputId": "ca844f80-108c-4f09-9728-087913d2b850"
   },
   "outputs": [],
   "source": [
    "epochs_range = range(1, epochs + 1)\n",
    "plt.plot(epochs_range, train_loss_history, 'ro', label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss_history, 'b', label='Validation Loss')\n",
    "\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:07:28.607971Z",
     "iopub.status.busy": "2023-10-03T10:07:28.607539Z",
     "iopub.status.idle": "2023-10-03T10:07:29.030844Z",
     "shell.execute_reply": "2023-10-03T10:07:29.030098Z",
     "shell.execute_reply.started": "2023-10-03T10:07:28.607937Z"
    },
    "id": "jrpQlKmLMaXP",
    "outputId": "8c650934-294a-4d0e-9f28-4c4e87caab29"
   },
   "outputs": [],
   "source": [
    "train_predicted = model(train_x).detach().numpy()\n",
    "val_predicted = model(val_x).detach().numpy()\n",
    "\n",
    "plt.plot(train_y, train_predicted, 'ro')\n",
    "plt.plot(val_y, val_predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF-NLRC0yyO4"
   },
   "source": [
    "## Testing\n",
    "test 資料集需要注意的事情是，我們會以每四筆輸入輸出一組預測結果。<br>\n",
    "也就是 test 資料共有 3984 筆資料，因此我們會預測出 996 筆結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:07:29.032163Z",
     "iopub.status.busy": "2023-10-03T10:07:29.031882Z",
     "iopub.status.idle": "2023-10-03T10:07:29.992417Z",
     "shell.execute_reply": "2023-10-03T10:07:29.991520Z",
     "shell.execute_reply.started": "2023-10-03T10:07:29.032139Z"
    },
    "id": "5weXyiQnyxx0",
    "outputId": "eea445aa-24f6-4533-96f6-0cf0691b535b"
   },
   "outputs": [],
   "source": [
    "def load_test_data(folder_path):\n",
    "  load_df = pd.DataFrame()\n",
    "  # 遍歷文件夾中的所有文件\n",
    "  name_list=[]\n",
    "  for filename in os.listdir(folder_path):\n",
    "      if filename.endswith(\".csv\"):\n",
    "          file_path = os.path.join(folder_path, filename)\n",
    "          df = pd.read_csv(file_path)\n",
    "#           load_df = pd.concat([load_df, df[\"現鈔買入\"], df[\"現鈔賣出\"], df[\"即期買入\"], df[\"即期賣出\"]], axis=1)\n",
    "          load_df = pd.concat([load_df, df[\"現鈔買入\"]], axis=1)\n",
    "          filename = filename.replace(\".csv\", \"\")\n",
    "          name_list.extend([f\"{filename}現鈔買入\"])\n",
    "  load_df.columns = name_list\n",
    "\n",
    "  # 反向排序\n",
    "  load_df = load_df.iloc[::-1]\n",
    "\n",
    "  # 排序column\n",
    "  load_df = load_df.reindex(sorted(load_df.columns), axis=1)\n",
    "\n",
    "  # 處理空值\n",
    "  load_df.replace(\"-\", 0, inplace=True)\n",
    "\n",
    "  return load_df\n",
    "\n",
    "#Kaggle 原路徑\n",
    "# test_df = load_test_data(\"/kaggle/input/2023-artificial-intelligence-hw1/Dataset/test\")\n",
    "\n",
    "test_df = load_test_data(\"./Dataset/test\")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:07:29.993528Z",
     "iopub.status.busy": "2023-10-03T10:07:29.993327Z",
     "iopub.status.idle": "2023-10-03T10:07:30.039007Z",
     "shell.execute_reply": "2023-10-03T10:07:30.038014Z",
     "shell.execute_reply.started": "2023-10-03T10:07:29.993511Z"
    },
    "id": "srG5Ubka0568"
   },
   "outputs": [],
   "source": [
    "test = test_df.to_numpy()\n",
    "test_size, feature_size = test.shape\n",
    "# 因為 test 資料已經事先切割好範圍，故需要明確切分每段資料\n",
    "test_size = test_size//input_date_data_size\n",
    "test_x = np.empty([test_size, feature_size * input_date_data_size], dtype = float)\n",
    "\n",
    "for idx in range(test_size):\n",
    "  temp_data = np.array([])\n",
    "  for count in range(input_date_data_size):\n",
    "    temp_data = np.hstack([temp_data, test[idx * input_date_data_size + count]])\n",
    "  test_x[idx, :] = temp_data\n",
    "\n",
    "# row_sums = test_x.sum(axis=1)\n",
    "# new_matrix = test_x / row_sums[:, np.newaxis]\n",
    "\n",
    "# test 資料也需要照 training 方式做正規化\n",
    "for i in range(len(test_x)):\n",
    "    for j in range(len(test_x[0])):\n",
    "        if std_x[j] != 0:\n",
    "            test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]\n",
    "\n",
    "# test_x = np.nan_to_num(test_x, nan=0)\n",
    "\n",
    "# min_val = np.min(test_x, axis=0)\n",
    "# max_val = np.max(test_x, axis=0)\n",
    "# print(test_x[0],min_val,max_val)\n",
    "\n",
    "# for i in range(len(test_x)):\n",
    "#     for j in range(len(test_x[0])):\n",
    "#         if max_val[j] - min_val[j] != 0:\n",
    "#             test_x[i][j] = (test_x[i][j] - min_val[j]) / (max_val[j] - min_val[j])\n",
    "#         else:\n",
    "#             test_x[i][j] = (test_x[i][j] - min_val[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T10:07:30.040265Z",
     "iopub.status.busy": "2023-10-03T10:07:30.040065Z",
     "iopub.status.idle": "2023-10-03T10:07:30.066772Z",
     "shell.execute_reply": "2023-10-03T10:07:30.065646Z",
     "shell.execute_reply.started": "2023-10-03T10:07:30.040248Z"
    },
    "id": "jEwbwr15zQDt"
   },
   "outputs": [],
   "source": [
    "test_x = torch.from_numpy(test_x.astype(np.float32))\n",
    "predicted = model(test_x)\n",
    "\n",
    "ids = [x for x in range(len(predicted))]\n",
    "output_df = pd.DataFrame({'id': ids})\n",
    "# 要按照規定順序設定col\n",
    "currency_columns = [\"AUD\", \"CAD\", \"EUR\", \"GBP\", \"HKD\", \"JPY\", \"KRW\", \"USD\"]\n",
    "\n",
    "for i, column_name in enumerate(currency_columns):\n",
    "    output_df[column_name] = [x[i] for x in predicted.tolist()]\n",
    "\n",
    "\n",
    "output_df.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
